{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "* prepare training data\n",
    "* dataset split into train, val, and eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from licai.data3d import RatioDataset\n",
    "\n",
    "ds = RatioDataset(data_dir='./Data/MITO/M1_U2OS', n_tform=6, is_tform=True)\n",
    "ds2 = RatioDataset(data_dir='./Data/MITO/M2_U2OS', n_tform=6, is_tform=True)\n",
    "ds.append(ds2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set:  ['./Data/MITO/M2_U2OS\\\\20210713-U2OS-NileRed-mito-007_ALN', './Data/MITO/M1_U2OS\\\\20210425-U2OS-NileRed-Mito-007_ALN', './Data/MITO/M1_U2OS\\\\20210425-U2OS-NileRed-Mito-001_ALN', './Data/MITO/M2_U2OS\\\\20210713-U2OS-NileRed-mito-014_ALN', './Data/MITO/M1_U2OS\\\\20210329-U2OS-NileRed-Mito-010_ALN', './Data/MITO/M2_U2OS\\\\20210817-U2OS-NileRed-Mito-015_ALN', './Data/MITO/M1_U2OS\\\\20210425-U2OS-NileRed-Mito-014_ALN', './Data/MITO/M2_U2OS\\\\20210817-U2OS-NileRed-Mito-010_ALN', './Data/MITO/M2_U2OS\\\\20210713-U2OS-NileRed-mito-030_ALN', './Data/MITO/M1_U2OS\\\\20210329-U2OS-NileRed-Mito-012_ALN', './Data/MITO/M2_U2OS\\\\20210713-U2OS-NileRed-mito-016_ALN', './Data/MITO/M1_U2OS\\\\20210425-U2OS-NileRed-Mito-006_ALN', './Data/MITO/M1_U2OS\\\\20210425-U2OS-NileRed-Mito-012_ALN', './Data/MITO/M1_U2OS\\\\20210425-U2OS-NileRed-Mito-002_ALN', './Data/MITO/M1_U2OS\\\\20210425-U2OS-NileRed-Mito-010_ALN', './Data/MITO/M2_U2OS\\\\20210814-U2OS-NileRed-Mito-004_ALN', './Data/MITO/M1_U2OS\\\\20210425-U2OS-NileRed-Mito-011_ALN', './Data/MITO/M2_U2OS\\\\20210814-U2OS-NileRed-Mito-008_ALN', './Data/MITO/M2_U2OS\\\\20210814-U2OS-NileRed-Mito-006_ALN', './Data/MITO/M1_U2OS\\\\20210329-U2OS-NileRed-Mito-003_ALN', './Data/MITO/M2_U2OS\\\\20210713-U2OS-NileRed-mito-018_ALN', './Data/MITO/M1_U2OS\\\\20210329-U2OS-NileRed-Mito-011_ALN', './Data/MITO/M1_U2OS\\\\20210425-U2OS-NileRed-Mito-004_ALN', './Data/MITO/M1_U2OS\\\\20210329-U2OS-NileRed-Mito-004_ALN']\n",
      "val set:  ['./Data/MITO/M2_U2OS\\\\20210814-U2OS-NileRed-Mito-001_ALN', './Data/MITO/M2_U2OS\\\\20210713-U2OS-NileRed-mito-001_ALN', './Data/MITO/M1_U2OS\\\\20210329-U2OS-NileRed-Mito-006_ALN', './Data/MITO/M2_U2OS\\\\20210814-U2OS-NileRed-Mito-002_ALN', './Data/MITO/M2_U2OS\\\\20210817-U2OS-NileRed-Mito-004_ALN', './Data/MITO/M1_U2OS\\\\20210329-U2OS-NileRed-Mito-008_ALN', './Data/MITO/M2_U2OS\\\\20210817-U2OS-NileRed-Mito-003_ALN', './Data/MITO/M2_U2OS\\\\20210713-U2OS-NileRed-mito-005_ALN']\n",
      "eval set:  ['./Data/MITO/M2_U2OS\\\\20210814-U2OS-NileRed-Mito-005_ALN', './Data/MITO/M1_U2OS\\\\20210425-U2OS-NileRed-Mito-003_ALN', './Data/MITO/M2_U2OS\\\\20210713-U2OS-NileRed-mito-004_ALN', './Data/MITO/M1_U2OS\\\\20210425-U2OS-NileRed-Mito-013_ALN', './Data/MITO/M1_U2OS\\\\20210425-U2OS-NileRed-Mito-015_ALN', './Data/MITO/M1_U2OS\\\\20210329-U2OS-NileRed-Mito-013_ALN', './Data/MITO/M1_U2OS\\\\20210425-U2OS-NileRed-Mito-009_ALN', './Data/MITO/M2_U2OS\\\\20210713-U2OS-NileRed-mito-027_ALN', './Data/MITO/M2_U2OS\\\\20210817-U2OS-NileRed-Mito-005_ALN']\n"
     ]
    }
   ],
   "source": [
    "from licai.model_base import BaseModel\n",
    "_, trainidx, validx, testidx = BaseModel.split_trainset(ds)\n",
    "print('train set: ', [ds.ids[x] for x in trainidx])\n",
    "print('val set: ', [ds.ids[x] for x in validx])\n",
    "print('eval set: ', [ds.ids[x] for x in testidx])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "* model file saved into exp/exp_name\n",
    "* losses and scores printed with loggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 72/72 [06:09<00:00,  5.14s/it, loss=0.625]\n",
      "Valid: 100%|██████████| 41/41 [04:31<00:00,  6.62s/it, loss=0.602]\n",
      "2023-03-10 22:03:47,310 Epochs: 0/300.. Epoch loss: 0.67442139, Train loss: 0.61424705, Val loss: 0.61520415, Test loss: 0.61764667, Train f1score: 32.2, Val f1score: 34.0, Test f1score: 32.0, Train recall: 69.8, Train precision: 22.0, lr: 2.0000\n",
      "Train: 100%|██████████| 72/72 [06:08<00:00,  5.12s/it, loss=0.592]\n",
      "Valid: 100%|██████████| 41/41 [02:53<00:00,  4.22s/it, loss=0.519]\n",
      "2023-03-10 22:12:49,450 Epochs: 1/300.. Epoch loss: 0.60961297, Train loss: 0.54012946, Val loss: 0.54123390, Test loss: 0.54618071, Train f1score: 34.1, Val f1score: 36.2, Test f1score: 35.0, Train recall: 67.4, Train precision: 24.0, lr: 2.0000\n",
      "Train: 100%|██████████| 72/72 [05:58<00:00,  4.98s/it, loss=0.546]\n",
      "Valid: 100%|██████████| 41/41 [02:17<00:00,  3.36s/it, loss=0.501]\n",
      "2023-03-10 22:21:06,289 Epochs: 2/300.. Epoch loss: 0.57085243, Train loss: 0.51246761, Val loss: 0.51536420, Test loss: 0.51811139, Train f1score: 38.1, Val f1score: 39.2, Test f1score: 38.8, Train recall: 57.5, Train precision: 31.2, lr: 2.0000\n",
      "Train: 100%|██████████| 72/72 [05:57<00:00,  4.97s/it, loss=0.54] \n",
      "Valid: 100%|██████████| 41/41 [02:18<00:00,  3.38s/it, loss=0.459]\n",
      "2023-03-10 22:29:22,662 Epochs: 3/300.. Epoch loss: 0.53942668, Train loss: 0.47214524, Val loss: 0.47424128, Test loss: 0.47898036, Train f1score: 38.9, Val f1score: 39.5, Test f1score: 39.6, Train recall: 62.1, Train precision: 30.6, lr: 2.0000\n",
      "Train: 100%|██████████| 72/72 [06:06<00:00,  5.09s/it, loss=0.481]\n",
      "Valid: 100%|██████████| 41/41 [02:18<00:00,  3.37s/it, loss=0.431]\n",
      "2023-03-10 22:37:47,810 Epochs: 4/300.. Epoch loss: 0.50422549, Train loss: 0.44524396, Val loss: 0.44701933, Test loss: 0.45223038, Train f1score: 40.1, Val f1score: 40.0, Test f1score: 40.3, Train recall: 42.2, Train precision: 43.0, lr: 2.0000\n",
      "Train: 100%|██████████| 72/72 [06:05<00:00,  5.07s/it, loss=0.443]\n",
      "Valid: 100%|██████████| 41/41 [02:19<00:00,  3.41s/it, loss=0.393]\n",
      "2023-03-10 22:46:12,955 Epochs: 5/300.. Epoch loss: 0.46804333, Train loss: 0.40768320, Val loss: 0.41046340, Test loss: 0.41354243, Train f1score: 38.4, Val f1score: 36.7, Test f1score: 37.6, Train recall: 35.3, Train precision: 49.2, lr: 2.0000\n",
      "Train: 100%|██████████| 72/72 [06:07<00:00,  5.11s/it, loss=0.417]\n",
      "Valid: 100%|██████████| 41/41 [02:17<00:00,  3.36s/it, loss=0.374]\n",
      "2023-03-10 22:54:38,989 Epochs: 6/300.. Epoch loss: 0.43298109, Train loss: 0.38435138, Val loss: 0.38777847, Test loss: 0.39005325, Train f1score: 46.2, Val f1score: 44.1, Test f1score: 45.8, Train recall: 63.3, Train precision: 39.9, lr: 2.0000\n",
      "Train: 100%|██████████| 72/72 [06:08<00:00,  5.11s/it, loss=0.389]\n",
      "Valid: 100%|██████████| 41/41 [02:18<00:00,  3.37s/it, loss=0.339]\n",
      "2023-03-10 23:03:05,451 Epochs: 7/300.. Epoch loss: 0.40091745, Train loss: 0.35059052, Val loss: 0.35418586, Test loss: 0.35478430, Train f1score: 47.7, Val f1score: 44.0, Test f1score: 45.9, Train recall: 55.5, Train precision: 46.5, lr: 2.0000\n",
      "Train: 100%|██████████| 72/72 [06:02<00:00,  5.03s/it, loss=0.358]\n",
      "Valid: 100%|██████████| 41/41 [02:18<00:00,  3.38s/it, loss=0.311]\n",
      "2023-03-10 23:11:26,274 Epochs: 8/300.. Epoch loss: 0.36905303, Train loss: 0.32277975, Val loss: 0.32656094, Test loss: 0.32743009, Train f1score: 48.4, Val f1score: 46.0, Test f1score: 48.2, Train recall: 59.8, Train precision: 44.6, lr: 2.0000\n",
      "Train: 100%|██████████| 72/72 [06:05<00:00,  5.08s/it, loss=0.309]\n",
      "Valid: 100%|██████████| 41/41 [02:18<00:00,  3.37s/it, loss=0.277]\n",
      "2023-03-10 23:19:50,309 Epochs: 9/300.. Epoch loss: 0.33920675, Train loss: 0.28914441, Val loss: 0.29279816, Test loss: 0.29444175, Train f1score: 48.4, Val f1score: 47.4, Test f1score: 49.4, Train recall: 60.5, Train precision: 44.0, lr: 2.0000\n",
      "Train: 100%|██████████| 72/72 [06:08<00:00,  5.11s/it, loss=0.309]\n",
      "Valid: 100%|██████████| 41/41 [02:17<00:00,  3.37s/it, loss=0.238]\n",
      "2023-03-10 23:28:16,670 Epochs: 10/300.. Epoch loss: 0.31346602, Train loss: 0.25335402, Val loss: 0.25819394, Test loss: 0.25807893, Train f1score: 50.7, Val f1score: 46.9, Test f1score: 50.8, Train recall: 50.6, Train precision: 54.5, lr: 2.0000\n",
      "Train: 100%|██████████| 72/72 [06:08<00:00,  5.12s/it, loss=0.256]\n",
      "Valid: 100%|██████████| 41/41 [02:18<00:00,  3.37s/it, loss=0.213]\n",
      "2023-03-10 23:36:43,436 Epochs: 11/300.. Epoch loss: 0.28796628, Train loss: 0.22865309, Val loss: 0.23380277, Test loss: 0.23530734, Train f1score: 46.3, Val f1score: 42.9, Test f1score: 47.2, Train recall: 38.1, Train precision: 62.8, lr: 2.0000\n",
      "Train: 100%|██████████| 72/72 [06:05<00:00,  5.08s/it, loss=0.229]\n",
      "Valid: 100%|██████████| 41/41 [02:17<00:00,  3.36s/it, loss=0.203]\n",
      "2023-03-10 23:45:07,452 Epochs: 12/300.. Epoch loss: 0.26480832, Train loss: 0.21560699, Val loss: 0.22038608, Test loss: 0.22026689, Train f1score: 40.9, Val f1score: 44.9, Test f1score: 44.3, Train recall: 33.5, Train precision: 62.8, lr: 2.0000\n",
      "Train: 100%|██████████| 72/72 [05:59<00:00,  5.00s/it, loss=0.227]\n",
      "Valid: 100%|██████████| 41/41 [02:17<00:00,  3.36s/it, loss=0.163]\n",
      "2023-03-10 23:53:25,288 Epochs: 13/300.. Epoch loss: 0.23741825, Train loss: 0.17923894, Val loss: 0.18480623, Test loss: 0.18501807, Train f1score: 42.2, Val f1score: 42.6, Test f1score: 42.5, Train recall: 33.6, Train precision: 63.7, lr: 2.0000\n",
      "Train: 100%|██████████| 72/72 [06:05<00:00,  5.08s/it, loss=0.215]\n",
      "Valid: 100%|██████████| 41/41 [02:18<00:00,  3.37s/it, loss=0.148]\n",
      "2023-03-11 00:01:49,439 Epochs: 14/300.. Epoch loss: 0.21584612, Train loss: 0.16749658, Val loss: 0.17396271, Test loss: 0.17436823, Train f1score: 49.3, Val f1score: 47.9, Test f1score: 50.1, Train recall: 76.7, Train precision: 37.9, lr: 2.0000\n",
      "Train: 100%|██████████| 72/72 [06:03<00:00,  5.05s/it, loss=0.163]\n",
      "Valid: 100%|██████████| 41/41 [02:17<00:00,  3.36s/it, loss=0.138]\n",
      "2023-03-11 00:10:11,498 Epochs: 15/300.. Epoch loss: 0.19928440, Train loss: 0.15583033, Val loss: 0.16421495, Test loss: 0.16158298, Train f1score: 55.3, Val f1score: 51.0, Test f1score: 55.8, Train recall: 62.2, Train precision: 51.2, lr: 2.0000\n",
      "Train: 100%|██████████| 72/72 [06:10<00:00,  5.14s/it, loss=0.171]\n",
      "Valid: 100%|██████████| 41/41 [02:18<00:00,  3.37s/it, loss=0.111]\n",
      "2023-03-11 00:18:40,165 Epochs: 16/300.. Epoch loss: 0.18421483, Train loss: 0.12893566, Val loss: 0.13672853, Test loss: 0.13579562, Train f1score: 48.5, Val f1score: 44.6, Test f1score: 47.6, Train recall: 43.1, Train precision: 58.8, lr: 2.0000\n",
      "Train: 100%|██████████| 72/72 [06:04<00:00,  5.06s/it, loss=0.163]\n",
      "Valid: 100%|██████████| 41/41 [02:18<00:00,  3.37s/it, loss=0.0971]\n",
      "2023-03-11 00:27:03,037 Epochs: 17/300.. Epoch loss: 0.16970762, Train loss: 0.11523003, Val loss: 0.12374267, Test loss: 0.12168001, Train f1score: 48.0, Val f1score: 43.2, Test f1score: 49.3, Train recall: 40.9, Train precision: 62.7, lr: 2.0000\n",
      "Train: 100%|██████████| 72/72 [06:14<00:00,  5.21s/it, loss=0.149]\n",
      "Valid: 100%|██████████| 41/41 [02:17<00:00,  3.36s/it, loss=0.0991]\n",
      "2023-03-11 00:35:36,002 Epochs: 18/300.. Epoch loss: 0.16011636, Train loss: 0.11657731, Val loss: 0.12456082, Test loss: 0.12295274, Train f1score: 54.3, Val f1score: 50.9, Test f1score: 54.8, Train recall: 66.8, Train precision: 46.8, lr: 2.0000\n",
      "Train: 100%|██████████| 72/72 [06:01<00:00,  5.01s/it, loss=0.149]\n",
      "Valid: 100%|██████████| 41/41 [02:18<00:00,  3.37s/it, loss=0.0841]\n",
      "2023-03-11 00:43:55,414 Epochs: 19/300.. Epoch loss: 0.14900268, Train loss: 0.09866658, Val loss: 0.10615587, Test loss: 0.10613742, Train f1score: 57.7, Val f1score: 54.0, Test f1score: 56.5, Train recall: 66.8, Train precision: 52.1, lr: 2.0000\n",
      "Train: 100%|██████████| 72/72 [05:56<00:00,  4.95s/it, loss=0.184] \n",
      "Valid: 100%|██████████| 41/41 [02:18<00:00,  3.37s/it, loss=0.0755]\n",
      "2023-03-11 00:52:10,687 Epochs: 20/300.. Epoch loss: 0.14252071, Train loss: 0.09292234, Val loss: 0.10086877, Test loss: 0.10068238, Train f1score: 53.3, Val f1score: 46.9, Test f1score: 51.8, Train recall: 47.6, Train precision: 63.3, lr: 2.0000\n",
      "Train: 100%|██████████| 72/72 [06:09<00:00,  5.13s/it, loss=0.123] \n",
      "Valid: 100%|██████████| 41/41 [02:18<00:00,  3.38s/it, loss=0.0683]\n",
      "2023-03-11 01:00:38,596 Epochs: 21/300.. Epoch loss: 0.13610325, Train loss: 0.08511406, Val loss: 0.09269945, Test loss: 0.09240424, Train f1score: 51.5, Val f1score: 50.2, Test f1score: 52.2, Train recall: 45.4, Train precision: 62.7, lr: 2.0000\n",
      "Train: 100%|██████████| 72/72 [06:03<00:00,  5.05s/it, loss=0.125] \n",
      "Valid: 100%|██████████| 41/41 [02:18<00:00,  3.38s/it, loss=0.0591]\n",
      "2023-03-11 01:09:00,570 Epochs: 22/300.. Epoch loss: 0.13434364, Train loss: 0.07802330, Val loss: 0.08731604, Test loss: 0.08548965, Train f1score: 50.3, Val f1score: 46.1, Test f1score: 48.6, Train recall: 41.0, Train precision: 68.6, lr: 2.0000\n",
      "Train: 100%|██████████| 72/72 [05:59<00:00,  5.00s/it, loss=0.13]  \n",
      "Valid: 100%|██████████| 41/41 [02:18<00:00,  3.37s/it, loss=0.0606]\n",
      "2023-03-11 01:17:18,830 Epochs: 23/300.. Epoch loss: 0.12714494, Train loss: 0.07813474, Val loss: 0.08718805, Test loss: 0.08589586, Train f1score: 58.5, Val f1score: 53.7, Test f1score: 58.3, Train recall: 67.6, Train precision: 52.6, lr: 2.0000\n",
      "Train: 100%|██████████| 72/72 [06:07<00:00,  5.11s/it, loss=0.0847]\n",
      "Valid: 100%|██████████| 41/41 [02:18<00:00,  3.37s/it, loss=0.0623]\n",
      "2023-03-11 01:25:44,514 Epochs: 24/300.. Epoch loss: 0.11773820, Train loss: 0.07926682, Val loss: 0.08625175, Test loss: 0.08558557, Train f1score: 53.3, Val f1score: 52.5, Test f1score: 55.0, Train recall: 52.5, Train precision: 56.7, lr: 2.0000\n",
      "Train: 100%|██████████| 72/72 [06:01<00:00,  5.02s/it, loss=0.123] \n",
      "Valid: 100%|██████████| 41/41 [02:17<00:00,  3.36s/it, loss=0.049] \n",
      "2023-03-11 01:34:03,545 Epochs: 25/300.. Epoch loss: 0.11819248, Train loss: 0.06946649, Val loss: 0.07827240, Test loss: 0.07772579, Train f1score: 54.6, Val f1score: 49.3, Test f1score: 51.0, Train recall: 50.4, Train precision: 62.9, lr: 2.0000\n",
      "Train: 100%|██████████| 72/72 [06:02<00:00,  5.04s/it, loss=0.0866]\n",
      "Valid: 100%|██████████| 41/41 [02:18<00:00,  3.37s/it, loss=0.0461]\n",
      "2023-03-11 01:42:24,757 Epochs: 26/300.. Epoch loss: 0.11669713, Train loss: 0.06508030, Val loss: 0.07481047, Test loss: 0.07513729, Train f1score: 55.4, Val f1score: 48.4, Test f1score: 52.7, Train recall: 52.0, Train precision: 61.5, lr: 2.0000\n",
      "Train: 100%|██████████| 72/72 [06:04<00:00,  5.07s/it, loss=0.117] \n",
      "Valid: 100%|██████████| 41/41 [02:17<00:00,  3.36s/it, loss=0.0515]\n",
      "2023-03-11 01:50:47,658 Epochs: 27/300.. Epoch loss: 0.10937196, Train loss: 0.07086183, Val loss: 0.07773994, Test loss: 0.07884822, Train f1score: 50.1, Val f1score: 50.6, Test f1score: 51.8, Train recall: 57.1, Train precision: 46.4, lr: 2.0000\n",
      "Train: 100%|██████████| 72/72 [06:00<00:00,  5.01s/it, loss=0.16]  \n",
      "Valid: 100%|██████████| 41/41 [02:18<00:00,  3.38s/it, loss=0.0423]\n",
      "2023-03-11 01:59:06,852 Epochs: 28/300.. Epoch loss: 0.11214132, Train loss: 0.06143930, Val loss: 0.07248083, Test loss: 0.06973641, Train f1score: 46.5, Val f1score: 39.6, Test f1score: 41.7, Train recall: 35.0, Train precision: 73.1, lr: 2.0000\n",
      "Train: 100%|██████████| 72/72 [05:59<00:00,  4.99s/it, loss=0.104] \n",
      "Valid: 100%|██████████| 41/41 [02:17<00:00,  3.37s/it, loss=0.041] \n",
      "2023-03-11 02:07:24,372 Epochs: 29/300.. Epoch loss: 0.10524210, Train loss: 0.05853678, Val loss: 0.06738197, Test loss: 0.06902605, Train f1score: 59.7, Val f1score: 54.2, Test f1score: 57.9, Train recall: 67.3, Train precision: 54.7, lr: 2.0000\n",
      "Train: 100%|██████████| 72/72 [06:12<00:00,  5.17s/it, loss=0.09]  \n",
      "Valid: 100%|██████████| 41/41 [02:18<00:00,  3.37s/it, loss=0.0415]\n",
      "2023-03-11 02:15:55,109 Epochs: 30/300.. Epoch loss: 0.10323724, Train loss: 0.06174007, Val loss: 0.07230765, Test loss: 0.07010580, Train f1score: 59.8, Val f1score: 54.9, Test f1score: 58.8, Train recall: 72.2, Train precision: 52.2, lr: 2.0000\n",
      "Train: 100%|██████████| 72/72 [06:06<00:00,  5.09s/it, loss=0.108] \n",
      "Valid: 100%|██████████| 41/41 [02:17<00:00,  3.36s/it, loss=0.0384]\n",
      "2023-03-11 02:24:19,535 Epochs: 31/300.. Epoch loss: 0.10122344, Train loss: 0.05601049, Val loss: 0.06619562, Test loss: 0.06453717, Train f1score: 58.1, Val f1score: 53.6, Test f1score: 55.7, Train recall: 57.7, Train precision: 60.9, lr: 2.0000\n",
      "Train: 100%|██████████| 72/72 [05:58<00:00,  4.98s/it, loss=0.0911]\n",
      "Valid: 100%|██████████| 41/41 [02:17<00:00,  3.36s/it, loss=0.0423]\n",
      "2023-03-11 02:32:36,281 Epochs: 32/300.. Epoch loss: 0.10165589, Train loss: 0.05820511, Val loss: 0.06782194, Test loss: 0.06797050, Train f1score: 54.5, Val f1score: 53.1, Test f1score: 53.9, Train recall: 58.0, Train precision: 55.1, lr: 2.0000\n",
      "Train: 100%|██████████| 72/72 [06:11<00:00,  5.16s/it, loss=0.121] \n",
      "Valid: 100%|██████████| 41/41 [02:18<00:00,  3.37s/it, loss=0.0388]\n",
      "2023-03-11 02:41:05,996 Epochs: 33/300.. Epoch loss: 0.09935913, Train loss: 0.05794301, Val loss: 0.07185732, Test loss: 0.07554220, Train f1score: 50.4, Val f1score: 44.0, Test f1score: 43.6, Train recall: 47.8, Train precision: 60.4, lr: 2.0000\n",
      "Train: 100%|██████████| 72/72 [06:05<00:00,  5.07s/it, loss=0.0996]\n",
      "Valid: 100%|██████████| 41/41 [02:18<00:00,  3.37s/it, loss=0.0355]\n",
      "2023-03-11 02:49:29,370 Epochs: 34/300.. Epoch loss: 0.09879962, Train loss: 0.05222200, Val loss: 0.06261465, Test loss: 0.06027028, Train f1score: 54.2, Val f1score: 51.3, Test f1score: 51.9, Train recall: 46.4, Train precision: 68.8, lr: 2.0000\n",
      "Train: 100%|██████████| 72/72 [06:05<00:00,  5.08s/it, loss=0.168] \n",
      "Valid: 100%|██████████| 41/41 [02:18<00:00,  3.37s/it, loss=0.0309]\n",
      "2023-03-11 02:57:53,720 Epochs: 35/300.. Epoch loss: 0.09815876, Train loss: 0.04786987, Val loss: 0.05860529, Test loss: 0.05682721, Train f1score: 58.0, Val f1score: 52.2, Test f1score: 53.7, Train recall: 52.0, Train precision: 68.1, lr: 2.0000\n",
      "Train: 100%|██████████| 72/72 [06:03<00:00,  5.04s/it, loss=0.0688]\n",
      "Valid: 100%|██████████| 41/41 [02:18<00:00,  3.37s/it, loss=0.0316]\n",
      "2023-03-11 03:06:15,120 Epochs: 36/300.. Epoch loss: 0.09319273, Train loss: 0.05097542, Val loss: 0.06109050, Test loss: 0.05821476, Train f1score: 57.3, Val f1score: 52.6, Test f1score: 53.5, Train recall: 52.1, Train precision: 66.3, lr: 2.0000\n",
      "Train: 100%|██████████| 72/72 [06:00<00:00,  5.00s/it, loss=0.0603]\n",
      "Valid: 100%|██████████| 41/41 [02:17<00:00,  3.36s/it, loss=0.0318]\n",
      "2023-03-11 03:14:33,187 Epochs: 37/300.. Epoch loss: 0.09682345, Train loss: 0.04888947, Val loss: 0.05980467, Test loss: 0.05749019, Train f1score: 61.2, Val f1score: 55.4, Test f1score: 57.9, Train recall: 61.4, Train precision: 62.2, lr: 2.0000\n",
      "Train: 100%|██████████| 72/72 [05:59<00:00,  5.00s/it, loss=0.105] \n",
      "Valid: 100%|██████████| 41/41 [02:17<00:00,  3.36s/it, loss=0.0314]\n",
      "2023-03-11 03:22:50,949 Epochs: 38/300.. Epoch loss: 0.08801544, Train loss: 0.05143714, Val loss: 0.06204729, Test loss: 0.05892496, Train f1score: 59.7, Val f1score: 54.9, Test f1score: 58.0, Train recall: 65.9, Train precision: 55.7, lr: 2.0000\n",
      "Train: 100%|██████████| 72/72 [06:10<00:00,  5.15s/it, loss=0.136] \n",
      "Valid: 100%|██████████| 41/41 [02:17<00:00,  3.36s/it, loss=0.0287]\n",
      "2023-03-11 03:31:19,414 Epochs: 39/300.. Epoch loss: 0.09336800, Train loss: 0.04710549, Val loss: 0.05769539, Test loss: 0.05546134, Train f1score: 61.6, Val f1score: 56.0, Test f1score: 58.7, Train recall: 70.2, Train precision: 55.7, lr: 2.0000\n",
      "Train: 100%|██████████| 72/72 [06:07<00:00,  5.11s/it, loss=0.0752]\n",
      "Valid: 100%|██████████| 41/41 [02:17<00:00,  3.36s/it, loss=0.0277]\n",
      "2023-03-11 03:39:45,132 Epochs: 40/300.. Epoch loss: 0.09344099, Train loss: 0.04667516, Val loss: 0.06051104, Test loss: 0.05531252, Train f1score: 61.7, Val f1score: 53.8, Test f1score: 57.9, Train recall: 65.5, Train precision: 60.3, lr: 2.0000\n",
      "Train: 100%|██████████| 72/72 [05:56<00:00,  4.95s/it, loss=0.115] \n",
      "Valid: 100%|██████████| 41/41 [02:18<00:00,  3.37s/it, loss=0.0264]\n",
      "2023-03-11 03:47:59,733 Epochs: 41/300.. Epoch loss: 0.09255758, Train loss: 0.04603222, Val loss: 0.05672981, Test loss: 0.05212581, Train f1score: 60.4, Val f1score: 55.8, Test f1score: 59.5, Train recall: 62.3, Train precision: 60.3, lr: 2.0000\n",
      "Train: 100%|██████████| 72/72 [06:04<00:00,  5.06s/it, loss=0.0576]\n",
      "Valid: 100%|██████████| 41/41 [02:18<00:00,  3.37s/it, loss=0.0265]\n",
      "2023-03-11 03:56:22,175 Epochs: 42/300.. Epoch loss: 0.08707491, Train loss: 0.04457969, Val loss: 0.05546397, Test loss: 0.05265309, Train f1score: 58.5, Val f1score: 54.8, Test f1score: 55.6, Train recall: 53.6, Train precision: 67.1, lr: 2.0000\n",
      "Train: 100%|██████████| 72/72 [06:01<00:00,  5.03s/it, loss=0.0429]\n",
      "Valid: 100%|██████████| 41/41 [02:18<00:00,  3.37s/it, loss=0.0262]\n",
      "2023-03-11 04:04:42,495 Epochs: 43/300.. Epoch loss: 0.08320044, Train loss: 0.04570923, Val loss: 0.05639557, Test loss: 0.05222920, Train f1score: 55.3, Val f1score: 53.0, Test f1score: 55.2, Train recall: 50.9, Train precision: 63.2, lr: 2.0000\n",
      "Train: 100%|██████████| 72/72 [05:58<00:00,  4.99s/it, loss=0.0612]\n",
      "Valid: 100%|██████████| 41/41 [02:17<00:00,  3.36s/it, loss=0.0257]\n",
      "2023-03-11 04:12:59,317 Epochs: 44/300.. Epoch loss: 0.08350921, Train loss: 0.04550368, Val loss: 0.05809966, Test loss: 0.05428444, Train f1score: 60.7, Val f1score: 54.5, Test f1score: 58.2, Train recall: 63.5, Train precision: 59.8, lr: 2.0000\n",
      "Train: 100%|██████████| 72/72 [06:01<00:00,  5.02s/it, loss=0.0643]\n",
      "Valid: 100%|██████████| 41/41 [02:17<00:00,  3.36s/it, loss=0.0237]\n",
      "2023-03-11 04:21:18,701 Epochs: 45/300.. Epoch loss: 0.08929108, Train loss: 0.04256389, Val loss: 0.05637870, Test loss: 0.05359807, Train f1score: 57.4, Val f1score: 51.2, Test f1score: 52.1, Train recall: 54.9, Train precision: 64.1, lr: 2.0000\n",
      "Train: 100%|██████████| 72/72 [06:06<00:00,  5.09s/it, loss=0.099] \n",
      "Valid: 100%|██████████| 41/41 [02:18<00:00,  3.37s/it, loss=0.0259]\n",
      "2023-03-11 04:29:43,508 Epochs: 46/300.. Epoch loss: 0.08514138, Train loss: 0.04265390, Val loss: 0.05527774, Test loss: 0.05150980, Train f1score: 58.2, Val f1score: 52.4, Test f1score: 54.5, Train recall: 51.1, Train precision: 70.2, lr: 2.0000\n",
      "Train: 100%|██████████| 72/72 [06:05<00:00,  5.08s/it, loss=0.0415]\n",
      "Valid: 100%|██████████| 41/41 [02:17<00:00,  3.36s/it, loss=0.0223]\n",
      "2023-03-11 04:38:07,180 Epochs: 47/300.. Epoch loss: 0.08513502, Train loss: 0.04107421, Val loss: 0.05270364, Test loss: 0.04892307, Train f1score: 60.4, Val f1score: 56.5, Test f1score: 58.9, Train recall: 63.9, Train precision: 59.0, lr: 2.0000\n",
      "Train: 100%|██████████| 72/72 [05:59<00:00,  4.99s/it, loss=0.0893]\n",
      "Valid: 100%|██████████| 41/41 [02:17<00:00,  3.37s/it, loss=0.0238]\n",
      "2023-03-11 04:46:24,560 Epochs: 48/300.. Epoch loss: 0.08053065, Train loss: 0.04236312, Val loss: 0.05424228, Test loss: 0.05132782, Train f1score: 60.6, Val f1score: 55.5, Test f1score: 58.2, Train recall: 59.9, Train precision: 64.7, lr: 2.0000\n",
      "Train: 100%|██████████| 72/72 [05:59<00:00,  4.99s/it, loss=0.0695]\n",
      "Valid: 100%|██████████| 41/41 [02:17<00:00,  3.36s/it, loss=0.0258]\n",
      "2023-03-11 04:54:41,547 Epochs: 49/300.. Epoch loss: 0.07549167, Train loss: 0.04696025, Val loss: 0.05861110, Test loss: 0.05748646, Train f1score: 59.9, Val f1score: 55.5, Test f1score: 57.2, Train recall: 71.7, Train precision: 52.4, lr: 2.0000\n",
      "Train: 100%|██████████| 72/72 [06:05<00:00,  5.08s/it, loss=0.161] \n",
      "Valid: 100%|██████████| 41/41 [02:18<00:00,  3.38s/it, loss=0.0233]\n",
      "2023-03-11 05:03:05,560 Epochs: 50/300.. Epoch loss: 0.08450835, Train loss: 0.04158260, Val loss: 0.05296726, Test loss: 0.05022522, Train f1score: 63.3, Val f1score: 57.3, Test f1score: 60.4, Train recall: 72.8, Train precision: 56.7, lr: 2.0000\n",
      "Train: 100%|██████████| 72/72 [06:06<00:00,  5.09s/it, loss=0.0952]\n",
      "Valid: 100%|██████████| 41/41 [02:17<00:00,  3.36s/it, loss=0.0232]\n",
      "2023-03-11 05:11:30,251 Epochs: 51/300.. Epoch loss: 0.08072831, Train loss: 0.04328308, Val loss: 0.05641446, Test loss: 0.05373556, Train f1score: 54.3, Val f1score: 48.0, Test f1score: 47.7, Train recall: 45.6, Train precision: 69.5, lr: 2.0000\n",
      "Train: 100%|██████████| 72/72 [06:00<00:00,  5.01s/it, loss=0.0481]\n",
      "Valid: 100%|██████████| 41/41 [02:18<00:00,  3.37s/it, loss=0.0205]\n",
      "2023-03-11 05:19:49,112 Epochs: 52/300.. Epoch loss: 0.08168859, Train loss: 0.03987360, Val loss: 0.05236564, Test loss: 0.05139708, Train f1score: 59.7, Val f1score: 51.3, Test f1score: 52.2, Train recall: 54.4, Train precision: 67.6, lr: 2.0000\n",
      "Train: 100%|██████████| 72/72 [06:06<00:00,  5.10s/it, loss=0.0623]\n",
      "Valid: 100%|██████████| 41/41 [02:18<00:00,  3.37s/it, loss=0.0256]\n",
      "2023-03-11 05:28:14,239 Epochs: 53/300.. Epoch loss: 0.08070076, Train loss: 0.04457196, Val loss: 0.06120905, Test loss: 0.05741723, Train f1score: 51.1, Val f1score: 40.5, Test f1score: 43.9, Train recall: 41.4, Train precision: 70.5, lr: 2.0000\n",
      "Train: 100%|██████████| 72/72 [06:06<00:00,  5.09s/it, loss=0.0848]\n",
      "Valid: 100%|██████████| 41/41 [02:18<00:00,  3.37s/it, loss=0.0211]\n",
      "2023-03-11 05:36:38,920 Epochs: 54/300.. Epoch loss: 0.07738045, Train loss: 0.03840142, Val loss: 0.05029311, Test loss: 0.04696230, Train f1score: 58.8, Val f1score: 53.7, Test f1score: 55.6, Train recall: 50.8, Train precision: 71.9, lr: 2.0000\n",
      "Train: 100%|██████████| 72/72 [06:03<00:00,  5.05s/it, loss=0.0659]\n",
      "Valid: 100%|██████████| 41/41 [02:17<00:00,  3.36s/it, loss=0.0221]\n",
      "2023-03-11 05:45:00,734 Epochs: 55/300.. Epoch loss: 0.07868595, Train loss: 0.03947212, Val loss: 0.05232472, Test loss: 0.05224730, Train f1score: 60.1, Val f1score: 52.4, Test f1score: 54.3, Train recall: 53.7, Train precision: 70.1, lr: 2.0000\n",
      "Train: 100%|██████████| 72/72 [06:06<00:00,  5.09s/it, loss=0.0567]\n",
      "Valid: 100%|██████████| 41/41 [02:17<00:00,  3.37s/it, loss=0.0194]\n",
      "2023-03-11 05:53:25,463 Epochs: 56/300.. Epoch loss: 0.07434651, Train loss: 0.03870462, Val loss: 0.05068186, Test loss: 0.04906482, Train f1score: 63.0, Val f1score: 56.5, Test f1score: 58.9, Train recall: 66.3, Train precision: 61.6, lr: 2.0000\n",
      "Train: 100%|██████████| 72/72 [06:00<00:00,  5.01s/it, loss=0.0914]\n",
      "Valid: 100%|██████████| 41/41 [02:17<00:00,  3.36s/it, loss=0.0199]\n",
      "2023-03-11 06:01:43,569 Epochs: 57/300.. Epoch loss: 0.07859782, Train loss: 0.03762773, Val loss: 0.05138106, Test loss: 0.04863447, Train f1score: 58.6, Val f1score: 51.0, Test f1score: 52.3, Train recall: 49.6, Train precision: 74.6, lr: 2.0000\n",
      "Train: 100%|██████████| 72/72 [06:05<00:00,  5.07s/it, loss=0.084] \n",
      "Valid: 100%|██████████| 41/41 [02:17<00:00,  3.36s/it, loss=0.0202]\n",
      "2023-03-11 06:10:06,544 Epochs: 58/300.. Epoch loss: 0.07459344, Train loss: 0.03679226, Val loss: 0.04853044, Test loss: 0.04618702, Train f1score: 62.8, Val f1score: 56.2, Test f1score: 57.9, Train recall: 58.9, Train precision: 68.4, lr: 2.0000\n",
      "Train: 100%|██████████| 72/72 [06:04<00:00,  5.06s/it, loss=0.0946]\n",
      "Valid: 100%|██████████| 41/41 [02:17<00:00,  3.36s/it, loss=0.0196]\n",
      "2023-03-11 06:18:28,896 Epochs: 59/300.. Epoch loss: 0.07438513, Train loss: 0.03883214, Val loss: 0.04941568, Test loss: 0.04763946, Train f1score: 63.8, Val f1score: 57.9, Test f1score: 59.8, Train recall: 74.8, Train precision: 56.4, lr: 2.0000\n",
      "Train: 100%|██████████| 72/72 [06:03<00:00,  5.04s/it, loss=0.0818]\n",
      "Valid: 100%|██████████| 41/41 [02:18<00:00,  3.38s/it, loss=0.0196]\n",
      "2023-03-11 06:26:50,558 Epochs: 60/300.. Epoch loss: 0.07669074, Train loss: 0.03736103, Val loss: 0.04898400, Test loss: 0.04745095, Train f1score: 61.3, Val f1score: 56.5, Test f1score: 56.5, Train recall: 56.2, Train precision: 69.6, lr: 2.0000\n",
      "Train: 100%|██████████| 72/72 [05:56<00:00,  4.95s/it, loss=0.0325]\n",
      "Valid: 100%|██████████| 41/41 [02:17<00:00,  3.36s/it, loss=0.0189]\n",
      "2023-03-11 06:35:04,928 Epochs: 61/300.. Epoch loss: 0.07648321, Train loss: 0.03693357, Val loss: 0.04935767, Test loss: 0.04666811, Train f1score: 63.9, Val f1score: 57.3, Test f1score: 59.2, Train recall: 62.8, Train precision: 66.2, lr: 2.0000\n",
      "Train: 100%|██████████| 72/72 [05:57<00:00,  4.96s/it, loss=0.13]  \n",
      "Valid: 100%|██████████| 41/41 [02:18<00:00,  3.37s/it, loss=0.0225]\n",
      "2023-03-11 06:43:20,112 Epochs: 62/300.. Epoch loss: 0.07592108, Train loss: 0.04109619, Val loss: 0.05399374, Test loss: 0.05473733, Train f1score: 55.4, Val f1score: 49.8, Test f1score: 47.5, Train recall: 47.3, Train precision: 70.1, lr: 2.0000\n",
      "Train: 100%|██████████| 72/72 [05:57<00:00,  4.97s/it, loss=0.0405]\n",
      "Valid: 100%|██████████| 41/41 [02:17<00:00,  3.35s/it, loss=0.0185]\n",
      "2023-03-11 06:51:35,238 Epochs: 63/300.. Epoch loss: 0.07580055, Train loss: 0.03799299, Val loss: 0.04875445, Test loss: 0.04808568, Train f1score: 64.3, Val f1score: 58.9, Test f1score: 61.0, Train recall: 74.4, Train precision: 57.7, lr: 2.0000\n",
      "Train: 100%|██████████| 72/72 [06:03<00:00,  5.05s/it, loss=0.0444]\n",
      "Valid: 100%|██████████| 41/41 [02:18<00:00,  3.38s/it, loss=0.0196]\n",
      "2023-03-11 06:59:57,283 Epochs: 64/300.. Epoch loss: 0.07778212, Train loss: 0.03756947, Val loss: 0.05253531, Test loss: 0.05116259, Train f1score: 59.2, Val f1score: 51.5, Test f1score: 50.9, Train recall: 52.8, Train precision: 69.2, lr: 2.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00065: reducing learning rate of group 0 to 6.0000e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 72/72 [06:01<00:00,  5.02s/it, loss=0.0781]\n",
      "Valid: 100%|██████████| 41/41 [02:18<00:00,  3.37s/it, loss=0.0182]\n",
      "2023-03-11 07:08:17,130 Epochs: 65/300.. Epoch loss: 0.07067349, Train loss: 0.03445743, Val loss: 0.04769470, Test loss: 0.04415256, Train f1score: 65.5, Val f1score: 57.3, Test f1score: 60.4, Train recall: 63.7, Train precision: 68.2, lr: 0.6000\n",
      "Train: 100%|██████████| 72/72 [06:06<00:00,  5.10s/it, loss=0.0548]\n",
      "Valid: 100%|██████████| 41/41 [02:18<00:00,  3.38s/it, loss=0.0171]\n",
      "2023-03-11 07:16:42,773 Epochs: 66/300.. Epoch loss: 0.06920672, Train loss: 0.03447800, Val loss: 0.04692724, Test loss: 0.04373596, Train f1score: 66.5, Val f1score: 60.1, Test f1score: 62.8, Train recall: 72.3, Train precision: 62.3, lr: 0.6000\n",
      "Train: 100%|██████████| 72/72 [06:00<00:00,  5.01s/it, loss=0.0561]\n",
      "Valid: 100%|██████████| 41/41 [02:17<00:00,  3.36s/it, loss=0.0177]\n",
      "2023-03-11 07:25:01,411 Epochs: 67/300.. Epoch loss: 0.06789682, Train loss: 0.03423627, Val loss: 0.04761781, Test loss: 0.04505752, Train f1score: 64.8, Val f1score: 56.7, Test f1score: 58.6, Train recall: 60.6, Train precision: 70.6, lr: 0.6000\n",
      "Train: 100%|██████████| 72/72 [05:58<00:00,  4.98s/it, loss=0.0543]\n",
      "Valid: 100%|██████████| 41/41 [02:17<00:00,  3.36s/it, loss=0.0179]\n",
      "2023-03-11 07:33:17,646 Epochs: 68/300.. Epoch loss: 0.06733140, Train loss: 0.03480172, Val loss: 0.04681154, Test loss: 0.04482529, Train f1score: 65.8, Val f1score: 59.6, Test f1score: 61.4, Train recall: 67.7, Train precision: 65.5, lr: 0.6000\n",
      "Train: 100%|██████████| 72/72 [06:01<00:00,  5.03s/it, loss=0.0925]\n",
      "Valid: 100%|██████████| 41/41 [02:17<00:00,  3.36s/it, loss=0.0178]\n",
      "2023-03-11 07:41:37,345 Epochs: 69/300.. Epoch loss: 0.06591745, Train loss: 0.03411760, Val loss: 0.04751241, Test loss: 0.04427839, Train f1score: 64.3, Val f1score: 57.4, Test f1score: 59.1, Train recall: 59.2, Train precision: 71.6, lr: 0.6000\n",
      "Train: 100%|██████████| 72/72 [06:02<00:00,  5.04s/it, loss=0.0729]\n",
      "Valid: 100%|██████████| 41/41 [02:17<00:00,  3.36s/it, loss=0.0176]\n",
      "2023-03-11 07:49:58,270 Epochs: 70/300.. Epoch loss: 0.06715682, Train loss: 0.03400685, Val loss: 0.04778175, Test loss: 0.04449088, Train f1score: 66.9, Val f1score: 58.9, Test f1score: 61.3, Train recall: 68.1, Train precision: 66.4, lr: 0.6000\n",
      "Train: 100%|██████████| 72/72 [06:05<00:00,  5.08s/it, loss=0.0496]\n",
      "Valid: 100%|██████████| 41/41 [02:18<00:00,  3.38s/it, loss=0.0178]\n",
      "2023-03-11 07:58:22,652 Epochs: 71/300.. Epoch loss: 0.06944716, Train loss: 0.03457763, Val loss: 0.04698472, Test loss: 0.04491962, Train f1score: 65.1, Val f1score: 58.8, Test f1score: 59.6, Train recall: 62.9, Train precision: 69.0, lr: 0.6000\n",
      "Train: 100%|██████████| 72/72 [06:10<00:00,  5.15s/it, loss=0.0458]\n",
      "Valid: 100%|██████████| 41/41 [08:40<00:00, 12.70s/it, loss=0.0174]\n",
      "2023-03-11 08:13:13,726 Epochs: 72/300.. Epoch loss: 0.06278802, Train loss: 0.03353663, Val loss: 0.04723879, Test loss: 0.04464249, Train f1score: 66.6, Val f1score: 57.6, Test f1score: 59.7, Train recall: 65.0, Train precision: 68.9, lr: 0.6000\n",
      "Train: 100%|██████████| 72/72 [08:54<00:00,  7.42s/it, loss=0.0708]\n",
      "Valid: 100%|██████████| 41/41 [11:15<00:00, 16.48s/it, loss=0.0172]  \n",
      "2023-03-11 08:33:23,796 Epochs: 73/300.. Epoch loss: 0.06885715, Train loss: 0.03312734, Val loss: 0.04644305, Test loss: 0.04407750, Train f1score: 67.2, Val f1score: 59.8, Test f1score: 61.7, Train recall: 68.3, Train precision: 66.7, lr: 0.6000\n",
      "Train: 100%|██████████| 72/72 [06:42<00:00,  5.58s/it, loss=0.0175]\n",
      "Valid: 100%|██████████| 41/41 [07:11<00:00, 10.52s/it, loss=0.017] \n",
      "2023-03-11 08:47:17,393 Epochs: 74/300.. Epoch loss: 0.06378218, Train loss: 0.03353479, Val loss: 0.04574233, Test loss: 0.04350934, Train f1score: 66.6, Val f1score: 59.9, Test f1score: 61.7, Train recall: 66.3, Train precision: 68.0, lr: 0.6000\n",
      "Train: 100%|██████████| 72/72 [06:15<00:00,  5.21s/it, loss=0.0855]\n",
      "Valid: 100%|██████████| 41/41 [09:20<00:00, 13.66s/it, loss=0.0176]\n",
      "2023-03-11 09:02:53,111 Epochs: 75/300.. Epoch loss: 0.07188865, Train loss: 0.03409423, Val loss: 0.04788349, Test loss: 0.04563261, Train f1score: 66.2, Val f1score: 58.5, Test f1score: 59.9, Train recall: 65.0, Train precision: 68.3, lr: 0.6000\n",
      "Train: 100%|██████████| 72/72 [06:51<00:00,  5.72s/it, loss=0.0452]\n",
      "Valid: 100%|██████████| 41/41 [09:44<00:00, 14.25s/it, loss=0.017] \n",
      "2023-03-11 09:19:28,825 Epochs: 76/300.. Epoch loss: 0.06582980, Train loss: 0.03345510, Val loss: 0.04686837, Test loss: 0.04474339, Train f1score: 66.6, Val f1score: 59.0, Test f1score: 60.2, Train recall: 66.5, Train precision: 67.8, lr: 0.6000\n",
      "Train: 100%|██████████| 72/72 [07:03<00:00,  5.88s/it, loss=0.0665]\n",
      "Valid: 100%|██████████| 41/41 [09:55<00:00, 14.53s/it, loss=0.0164]\n",
      "2023-03-11 09:36:28,226 Epochs: 77/300.. Epoch loss: 0.06462818, Train loss: 0.03310213, Val loss: 0.04684378, Test loss: 0.04467759, Train f1score: 66.1, Val f1score: 57.8, Test f1score: 59.0, Train recall: 63.1, Train precision: 70.3, lr: 0.6000\n",
      "Train: 100%|██████████| 72/72 [06:04<00:00,  5.06s/it, loss=0.0529] \n",
      "Valid: 100%|██████████| 41/41 [02:24<00:00,  3.54s/it, loss=0.0171]\n",
      "2023-03-11 09:44:57,868 Epochs: 78/300.. Epoch loss: 0.06537245, Train loss: 0.03306592, Val loss: 0.04538582, Test loss: 0.04376540, Train f1score: 65.5, Val f1score: 59.2, Test f1score: 60.0, Train recall: 61.3, Train precision: 71.7, lr: 0.6000\n",
      "Train: 100%|██████████| 72/72 [06:08<00:00,  5.11s/it, loss=0.0287]\n",
      "Valid: 100%|██████████| 41/41 [02:21<00:00,  3.45s/it, loss=0.0175]\n",
      "2023-03-11 09:53:27,581 Epochs: 79/300.. Epoch loss: 0.06801488, Train loss: 0.03375263, Val loss: 0.04742889, Test loss: 0.04528019, Train f1score: 66.4, Val f1score: 58.1, Test f1score: 59.7, Train recall: 64.4, Train precision: 69.3, lr: 0.6000\n",
      "Train: 100%|██████████| 72/72 [06:09<00:00,  5.14s/it, loss=0.102] \n",
      "Valid: 100%|██████████| 41/41 [02:19<00:00,  3.41s/it, loss=0.0177]\n",
      "2023-03-11 10:01:57,201 Epochs: 80/300.. Epoch loss: 0.06653178, Train loss: 0.03380165, Val loss: 0.04761179, Test loss: 0.04641474, Train f1score: 65.5, Val f1score: 57.3, Test f1score: 58.1, Train recall: 62.8, Train precision: 69.8, lr: 0.6000\n",
      "Train: 100%|██████████| 72/72 [06:00<00:00,  5.00s/it, loss=0.0938]\n",
      "Valid: 100%|██████████| 41/41 [02:06<00:00,  3.08s/it, loss=0.018] \n",
      "2023-03-11 10:10:03,550 Epochs: 81/300.. Epoch loss: 0.06834982, Train loss: 0.03481588, Val loss: 0.05042368, Test loss: 0.04834794, Train f1score: 64.3, Val f1score: 55.0, Test f1score: 55.7, Train recall: 60.5, Train precision: 69.4, lr: 0.6000\n",
      "Train: 100%|██████████| 72/72 [05:54<00:00,  4.93s/it, loss=0.102] \n",
      "Valid: 100%|██████████| 41/41 [02:06<00:00,  3.09s/it, loss=0.0177]\n",
      "2023-03-11 10:18:04,847 Epochs: 82/300.. Epoch loss: 0.06512391, Train loss: 0.03449256, Val loss: 0.04896495, Test loss: 0.04607793, Train f1score: 65.5, Val f1score: 57.8, Test f1score: 59.3, Train recall: 63.2, Train precision: 68.8, lr: 0.6000\n",
      "Train: 100%|██████████| 72/72 [05:51<00:00,  4.88s/it, loss=0.0695]\n",
      "Valid: 100%|██████████| 41/41 [02:06<00:00,  3.09s/it, loss=0.0171]\n",
      "2023-03-11 10:26:02,650 Epochs: 83/300.. Epoch loss: 0.06351729, Train loss: 0.03309365, Val loss: 0.04685311, Test loss: 0.04394591, Train f1score: 64.6, Val f1score: 56.4, Test f1score: 58.8, Train recall: 58.7, Train precision: 72.9, lr: 0.6000\n",
      "Train: 100%|██████████| 72/72 [05:42<00:00,  4.76s/it, loss=0.0312] \n",
      "Valid: 100%|██████████| 41/41 [02:06<00:00,  3.08s/it, loss=0.0165]\n",
      "2023-03-11 10:33:51,733 Epochs: 84/300.. Epoch loss: 0.06243149, Train loss: 0.03295590, Val loss: 0.04681267, Test loss: 0.04306968, Train f1score: 67.7, Val f1score: 60.0, Test f1score: 63.1, Train recall: 69.2, Train precision: 66.9, lr: 0.6000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00085: reducing learning rate of group 0 to 1.8000e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 72/72 [05:46<00:00,  4.81s/it, loss=0.0215]\n",
      "Valid: 100%|██████████| 41/41 [02:06<00:00,  3.08s/it, loss=0.0173]\n",
      "2023-03-11 10:41:44,896 Epochs: 85/300.. Epoch loss: 0.06976043, Train loss: 0.03321368, Val loss: 0.04700300, Test loss: 0.04407638, Train f1score: 65.7, Val f1score: 58.5, Test f1score: 60.1, Train recall: 61.0, Train precision: 72.2, lr: 0.1800\n",
      "Train: 100%|██████████| 72/72 [05:47<00:00,  4.82s/it, loss=0.0419] \n",
      "Valid: 100%|██████████| 41/41 [02:06<00:00,  3.09s/it, loss=0.0166]\n",
      "2023-03-11 10:49:38,797 Epochs: 86/300.. Epoch loss: 0.06128430, Train loss: 0.03226445, Val loss: 0.04596075, Test loss: 0.04269070, Train f1score: 67.7, Val f1score: 59.8, Test f1score: 62.6, Train recall: 66.9, Train precision: 69.5, lr: 0.1800\n",
      "Train: 100%|██████████| 72/72 [05:49<00:00,  4.86s/it, loss=0.14]   \n",
      "Valid: 100%|██████████| 41/41 [02:06<00:00,  3.09s/it, loss=0.0166]\n",
      "2023-03-11 10:57:35,421 Epochs: 87/300.. Epoch loss: 0.06142219, Train loss: 0.03212518, Val loss: 0.04646797, Test loss: 0.04399895, Train f1score: 67.5, Val f1score: 59.1, Test f1score: 60.6, Train recall: 65.7, Train precision: 70.1, lr: 0.1800\n",
      "Train: 100%|██████████| 72/72 [05:46<00:00,  4.81s/it, loss=0.0511]\n",
      "Valid: 100%|██████████| 41/41 [02:07<00:00,  3.10s/it, loss=0.0165]\n",
      "2023-03-11 11:05:28,539 Epochs: 88/300.. Epoch loss: 0.06467603, Train loss: 0.03232821, Val loss: 0.04659323, Test loss: 0.04432587, Train f1score: 67.1, Val f1score: 59.0, Test f1score: 60.3, Train recall: 64.7, Train precision: 70.5, lr: 0.1800\n",
      "Train: 100%|██████████| 72/72 [05:44<00:00,  4.79s/it, loss=0.048] \n",
      "Valid: 100%|██████████| 41/41 [02:06<00:00,  3.08s/it, loss=0.0161]\n",
      "2023-03-11 11:13:19,431 Epochs: 89/300.. Epoch loss: 0.06391010, Train loss: 0.03183639, Val loss: 0.04529680, Test loss: 0.04350910, Train f1score: 68.4, Val f1score: 60.4, Test f1score: 62.2, Train recall: 70.1, Train precision: 67.5, lr: 0.1800\n",
      "Train: 100%|██████████| 72/72 [05:51<00:00,  4.88s/it, loss=0.0701]\n",
      "Valid: 100%|██████████| 41/41 [02:06<00:00,  3.09s/it, loss=0.0163]\n",
      "2023-03-11 11:21:17,553 Epochs: 90/300.. Epoch loss: 0.06080642, Train loss: 0.03198992, Val loss: 0.04540785, Test loss: 0.04376129, Train f1score: 68.1, Val f1score: 60.2, Test f1score: 61.5, Train recall: 68.0, Train precision: 68.9, lr: 0.1800\n",
      "Train: 100%|██████████| 72/72 [05:43<00:00,  4.77s/it, loss=0.025] \n",
      "Valid: 100%|██████████| 41/41 [02:06<00:00,  3.08s/it, loss=0.0165]\n",
      "2023-03-11 11:29:07,364 Epochs: 91/300.. Epoch loss: 0.06249067, Train loss: 0.03258855, Val loss: 0.04627550, Test loss: 0.04326275, Train f1score: 67.4, Val f1score: 59.9, Test f1score: 61.8, Train recall: 66.0, Train precision: 69.7, lr: 0.1800\n",
      "Train: 100%|██████████| 72/72 [05:40<00:00,  4.73s/it, loss=0.061] \n",
      "Valid: 100%|██████████| 41/41 [02:06<00:00,  3.08s/it, loss=0.0163]\n",
      "2023-03-11 11:36:53,676 Epochs: 92/300.. Epoch loss: 0.06374574, Train loss: 0.03201843, Val loss: 0.04685654, Test loss: 0.04416654, Train f1score: 67.4, Val f1score: 58.6, Test f1score: 60.6, Train recall: 65.8, Train precision: 69.9, lr: 0.1800\n",
      "Train: 100%|██████████| 72/72 [05:40<00:00,  4.73s/it, loss=0.0584]\n",
      "Valid: 100%|██████████| 41/41 [02:06<00:00,  3.08s/it, loss=0.0158]\n",
      "2023-03-11 11:44:40,920 Epochs: 93/300.. Epoch loss: 0.06465534, Train loss: 0.03135547, Val loss: 0.04578798, Test loss: 0.04349678, Train f1score: 67.7, Val f1score: 58.8, Test f1score: 60.9, Train recall: 66.3, Train precision: 70.2, lr: 0.1800\n",
      "Train: 100%|██████████| 72/72 [05:47<00:00,  4.83s/it, loss=0.0876]\n",
      "Valid: 100%|██████████| 41/41 [02:06<00:00,  3.08s/it, loss=0.016] \n",
      "2023-03-11 11:52:34,955 Epochs: 94/300.. Epoch loss: 0.06414892, Train loss: 0.03180153, Val loss: 0.04541834, Test loss: 0.04310028, Train f1score: 67.7, Val f1score: 59.8, Test f1score: 61.6, Train recall: 66.6, Train precision: 69.7, lr: 0.1800\n",
      "Train: 100%|██████████| 72/72 [05:49<00:00,  4.86s/it, loss=0.0496]\n",
      "Valid: 100%|██████████| 41/41 [02:06<00:00,  3.09s/it, loss=0.016] \n",
      "2023-03-11 12:00:31,801 Epochs: 95/300.. Epoch loss: 0.06306782, Train loss: 0.03173249, Val loss: 0.04640233, Test loss: 0.04403041, Train f1score: 67.8, Val f1score: 59.1, Test f1score: 60.8, Train recall: 66.7, Train precision: 69.7, lr: 0.1800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00096: reducing learning rate of group 0 to 5.4000e-06.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 72/72 [05:50<00:00,  4.87s/it, loss=0.0476]\n",
      "Valid: 100%|██████████| 41/41 [02:06<00:00,  3.08s/it, loss=0.0162]\n",
      "2023-03-11 12:08:28,787 Epochs: 96/300.. Epoch loss: 0.06634763, Train loss: 0.03194169, Val loss: 0.04608529, Test loss: 0.04320047, Train f1score: 66.9, Val f1score: 58.8, Test f1score: 60.9, Train recall: 63.1, Train precision: 72.2, lr: 0.0540\n",
      "Train: 100%|██████████| 72/72 [05:48<00:00,  4.85s/it, loss=0.0552]\n",
      "Valid: 100%|██████████| 41/41 [02:06<00:00,  3.08s/it, loss=0.0163]\n",
      "2023-03-11 12:16:23,972 Epochs: 97/300.. Epoch loss: 0.06235258, Train loss: 0.03210104, Val loss: 0.04594672, Test loss: 0.04353445, Train f1score: 68.0, Val f1score: 60.0, Test f1score: 61.7, Train recall: 67.9, Train precision: 69.0, lr: 0.0540\n",
      "Train: 100%|██████████| 72/72 [05:46<00:00,  4.81s/it, loss=0.0501]\n",
      "Valid: 100%|██████████| 41/41 [02:06<00:00,  3.09s/it, loss=0.016] \n",
      "2023-03-11 12:24:17,260 Epochs: 98/300.. Epoch loss: 0.06241428, Train loss: 0.03182514, Val loss: 0.04699682, Test loss: 0.04413038, Train f1score: 67.4, Val f1score: 58.3, Test f1score: 60.4, Train recall: 64.4, Train precision: 71.4, lr: 0.0540\n",
      "Train: 100%|██████████| 72/72 [05:48<00:00,  4.84s/it, loss=0.0361]\n",
      "Valid: 100%|██████████| 41/41 [02:06<00:00,  3.09s/it, loss=0.0162]\n",
      "2023-03-11 12:32:12,202 Epochs: 99/300.. Epoch loss: 0.06418045, Train loss: 0.03187136, Val loss: 0.04611394, Test loss: 0.04338436, Train f1score: 67.6, Val f1score: 59.3, Test f1score: 61.1, Train recall: 65.4, Train precision: 70.8, lr: 0.0540\n",
      "Train: 100%|██████████| 72/72 [05:47<00:00,  4.83s/it, loss=0.0568]\n",
      "Valid: 100%|██████████| 41/41 [02:06<00:00,  3.07s/it, loss=0.0161]\n",
      "2023-03-11 12:40:05,844 Epochs: 100/300.. Epoch loss: 0.06198855, Train loss: 0.03221606, Val loss: 0.04669376, Test loss: 0.04332982, Train f1score: 67.6, Val f1score: 59.2, Test f1score: 61.7, Train recall: 65.8, Train precision: 70.2, lr: 0.0540\n",
      "Train: 100%|██████████| 72/72 [05:44<00:00,  4.79s/it, loss=0.046] \n",
      "Valid: 100%|██████████| 41/41 [02:06<00:00,  3.09s/it, loss=0.016] \n",
      "2023-03-11 12:47:57,042 Epochs: 101/300.. Epoch loss: 0.06264187, Train loss: 0.03159343, Val loss: 0.04560843, Test loss: 0.04305874, Train f1score: 68.3, Val f1score: 60.0, Test f1score: 62.1, Train recall: 67.9, Train precision: 69.4, lr: 0.0540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00102: reducing learning rate of group 0 to 1.6200e-06.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 72/72 [05:47<00:00,  4.82s/it, loss=0.0447]\n",
      "Valid: 100%|██████████| 41/41 [02:06<00:00,  3.08s/it, loss=0.0161]\n",
      "2023-03-11 12:55:50,278 Epochs: 102/300.. Epoch loss: 0.06266723, Train loss: 0.03164298, Val loss: 0.04605045, Test loss: 0.04308913, Train f1score: 68.0, Val f1score: 59.5, Test f1score: 61.7, Train recall: 66.3, Train precision: 70.5, lr: 0.0162\n",
      "Train: 100%|██████████| 72/72 [05:49<00:00,  4.85s/it, loss=0.0767] \n",
      "Valid: 100%|██████████| 41/41 [02:06<00:00,  3.08s/it, loss=0.0159]\n",
      "2023-03-11 13:03:46,037 Epochs: 103/300.. Epoch loss: 0.06083886, Train loss: 0.03170997, Val loss: 0.04652033, Test loss: 0.04374853, Train f1score: 68.1, Val f1score: 59.3, Test f1score: 61.3, Train recall: 67.1, Train precision: 69.8, lr: 0.0162\n",
      "Train: 100%|██████████| 72/72 [05:47<00:00,  4.83s/it, loss=0.0634]\n",
      "Valid: 100%|██████████| 41/41 [02:06<00:00,  3.09s/it, loss=0.016] \n",
      "2023-03-11 13:11:40,569 Epochs: 104/300.. Epoch loss: 0.06284092, Train loss: 0.03181545, Val loss: 0.04590749, Test loss: 0.04315411, Train f1score: 68.1, Val f1score: 60.0, Test f1score: 61.9, Train recall: 67.3, Train precision: 69.6, lr: 0.0162\n",
      "Train: 100%|██████████| 72/72 [05:52<00:00,  4.89s/it, loss=0.0562]\n",
      "Valid: 100%|██████████| 41/41 [02:06<00:00,  3.08s/it, loss=0.0161]\n",
      "2023-03-11 13:19:38,836 Epochs: 105/300.. Epoch loss: 0.06354302, Train loss: 0.03198632, Val loss: 0.04696106, Test loss: 0.04443264, Train f1score: 67.4, Val f1score: 58.7, Test f1score: 60.4, Train recall: 64.4, Train precision: 71.4, lr: 0.0162\n",
      "Train: 100%|██████████| 72/72 [05:54<00:00,  4.92s/it, loss=0.00912]\n",
      "Valid: 100%|██████████| 41/41 [02:07<00:00,  3.10s/it, loss=0.0163]\n",
      "2023-03-11 13:27:40,424 Epochs: 106/300.. Epoch loss: 0.05693165, Train loss: 0.03202961, Val loss: 0.04584735, Test loss: 0.04306745, Train f1score: 68.0, Val f1score: 60.0, Test f1score: 62.1, Train recall: 67.0, Train precision: 69.8, lr: 0.0162\n",
      "Train: 100%|██████████| 72/72 [05:46<00:00,  4.82s/it, loss=0.0641]\n",
      "Valid: 100%|██████████| 41/41 [02:06<00:00,  3.09s/it, loss=0.0162]\n",
      "2023-03-11 13:35:33,982 Epochs: 107/300.. Epoch loss: 0.06215100, Train loss: 0.03166039, Val loss: 0.04606631, Test loss: 0.04319816, Train f1score: 68.1, Val f1score: 59.6, Test f1score: 61.8, Train recall: 66.6, Train precision: 70.4, lr: 0.0162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00108: reducing learning rate of group 0 to 4.8600e-07.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<RootLogger root (INFO)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from licai.model_nets import AttUnet3D_model\n",
    "exp_name = 'E2_M1M2_MITO_U2OS'\n",
    "is_resume = False\n",
    "model = AttUnet3D_model(exp_name=exp_name, device='cuda', n_channels=2, n_classes=1, pos_weights=1.5)\n",
    "if is_resume:\n",
    "    model.load(type='unet3d')\n",
    "model.train_ds(ds, batch_size=2, nepoch=300, lr=2e-4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation and inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Valid: 100%|███████████████████████████████████████████████████████████████████████████| 13/13 [00:37<00:00,  2.88s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataname</th>\n",
       "      <th>acc</th>\n",
       "      <th>moc</th>\n",
       "      <th>f1score</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>ntp</th>\n",
       "      <th>nfp</th>\n",
       "      <th>ntn</th>\n",
       "      <th>tfn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M2_001</td>\n",
       "      <td>0.99829</td>\n",
       "      <td>0.1668149</td>\n",
       "      <td>0.151253</td>\n",
       "      <td>0.106402</td>\n",
       "      <td>0.26147</td>\n",
       "      <td>1647</td>\n",
       "      <td>4651</td>\n",
       "      <td>10785655</td>\n",
       "      <td>13831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M2_002</td>\n",
       "      <td>0.995749</td>\n",
       "      <td>0.702773</td>\n",
       "      <td>0.702267</td>\n",
       "      <td>0.729675</td>\n",
       "      <td>0.676845</td>\n",
       "      <td>54174</td>\n",
       "      <td>25864</td>\n",
       "      <td>10705677</td>\n",
       "      <td>20069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M2_003</td>\n",
       "      <td>0.996554</td>\n",
       "      <td>0.4216778</td>\n",
       "      <td>0.420734</td>\n",
       "      <td>0.450643</td>\n",
       "      <td>0.394549</td>\n",
       "      <td>13522</td>\n",
       "      <td>20749</td>\n",
       "      <td>10755030</td>\n",
       "      <td>16483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M2_004</td>\n",
       "      <td>0.99677</td>\n",
       "      <td>0.5123837</td>\n",
       "      <td>0.504387</td>\n",
       "      <td>0.611984</td>\n",
       "      <td>0.428968</td>\n",
       "      <td>17761</td>\n",
       "      <td>23642</td>\n",
       "      <td>10753121</td>\n",
       "      <td>11260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M2_005</td>\n",
       "      <td>0.992679</td>\n",
       "      <td>0.4543718</td>\n",
       "      <td>0.439925</td>\n",
       "      <td>0.586642</td>\n",
       "      <td>0.351914</td>\n",
       "      <td>31068</td>\n",
       "      <td>57214</td>\n",
       "      <td>10695612</td>\n",
       "      <td>21890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M2_006</td>\n",
       "      <td>0.996884</td>\n",
       "      <td>0.6078525</td>\n",
       "      <td>0.607835</td>\n",
       "      <td>0.606085</td>\n",
       "      <td>0.609597</td>\n",
       "      <td>26095</td>\n",
       "      <td>16711</td>\n",
       "      <td>10746019</td>\n",
       "      <td>16959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M2_007</td>\n",
       "      <td>0.99902</td>\n",
       "      <td>0.5674125</td>\n",
       "      <td>0.561781</td>\n",
       "      <td>0.492813</td>\n",
       "      <td>0.653195</td>\n",
       "      <td>6788</td>\n",
       "      <td>3603</td>\n",
       "      <td>10788408</td>\n",
       "      <td>6985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M2_008</td>\n",
       "      <td>0.995644</td>\n",
       "      <td>0.5231678</td>\n",
       "      <td>0.48848</td>\n",
       "      <td>0.359705</td>\n",
       "      <td>0.760876</td>\n",
       "      <td>22474</td>\n",
       "      <td>7062</td>\n",
       "      <td>10736244</td>\n",
       "      <td>40004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M2_009</td>\n",
       "      <td>0.992505</td>\n",
       "      <td>0.32131988</td>\n",
       "      <td>0.319969</td>\n",
       "      <td>0.352153</td>\n",
       "      <td>0.293176</td>\n",
       "      <td>19055</td>\n",
       "      <td>45939</td>\n",
       "      <td>10705736</td>\n",
       "      <td>35054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M2_010</td>\n",
       "      <td>0.998144</td>\n",
       "      <td>0.1511031</td>\n",
       "      <td>0.055561</td>\n",
       "      <td>0.02879</td>\n",
       "      <td>0.791946</td>\n",
       "      <td>590</td>\n",
       "      <td>154</td>\n",
       "      <td>10785138</td>\n",
       "      <td>19902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M2_011</td>\n",
       "      <td>0.998371</td>\n",
       "      <td>0.77803046</td>\n",
       "      <td>0.777585</td>\n",
       "      <td>0.752702</td>\n",
       "      <td>0.80417</td>\n",
       "      <td>30778</td>\n",
       "      <td>7494</td>\n",
       "      <td>10757401</td>\n",
       "      <td>10111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M2_012</td>\n",
       "      <td>0.994368</td>\n",
       "      <td>0.40786827</td>\n",
       "      <td>0.380795</td>\n",
       "      <td>0.593323</td>\n",
       "      <td>0.280368</td>\n",
       "      <td>18714</td>\n",
       "      <td>48033</td>\n",
       "      <td>10726211</td>\n",
       "      <td>12826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M2_013</td>\n",
       "      <td>0.997998</td>\n",
       "      <td>0.64346856</td>\n",
       "      <td>0.642826</td>\n",
       "      <td>0.672354</td>\n",
       "      <td>0.615784</td>\n",
       "      <td>19468</td>\n",
       "      <td>12146</td>\n",
       "      <td>10764684</td>\n",
       "      <td>9486</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataname       acc         moc   f1score    recall precision    ntp    nfp  \\\n",
       "0   M2_001   0.99829   0.1668149  0.151253  0.106402   0.26147   1647   4651   \n",
       "0   M2_002  0.995749    0.702773  0.702267  0.729675  0.676845  54174  25864   \n",
       "0   M2_003  0.996554   0.4216778  0.420734  0.450643  0.394549  13522  20749   \n",
       "0   M2_004   0.99677   0.5123837  0.504387  0.611984  0.428968  17761  23642   \n",
       "0   M2_005  0.992679   0.4543718  0.439925  0.586642  0.351914  31068  57214   \n",
       "0   M2_006  0.996884   0.6078525  0.607835  0.606085  0.609597  26095  16711   \n",
       "0   M2_007   0.99902   0.5674125  0.561781  0.492813  0.653195   6788   3603   \n",
       "0   M2_008  0.995644   0.5231678   0.48848  0.359705  0.760876  22474   7062   \n",
       "0   M2_009  0.992505  0.32131988  0.319969  0.352153  0.293176  19055  45939   \n",
       "0   M2_010  0.998144   0.1511031  0.055561   0.02879  0.791946    590    154   \n",
       "0   M2_011  0.998371  0.77803046  0.777585  0.752702   0.80417  30778   7494   \n",
       "0   M2_012  0.994368  0.40786827  0.380795  0.593323  0.280368  18714  48033   \n",
       "0   M2_013  0.997998  0.64346856  0.642826  0.672354  0.615784  19468  12146   \n",
       "\n",
       "        ntn    tfn  \n",
       "0  10785655  13831  \n",
       "0  10705677  20069  \n",
       "0  10755030  16483  \n",
       "0  10753121  11260  \n",
       "0  10695612  21890  \n",
       "0  10746019  16959  \n",
       "0  10788408   6985  \n",
       "0  10736244  40004  \n",
       "0  10705736  35054  \n",
       "0  10785138  19902  \n",
       "0  10757401  10111  \n",
       "0  10726211  12826  \n",
       "0  10764684   9486  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saveinfo = {'issave':True, 'save_name':'pred_GOLGIm'}  \n",
    "model.eval_ds(ds, saveinfo)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "9028688467fa4a3aad7d9335dc53b72b5d006830e485718c084b471f9dc9d7ba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
